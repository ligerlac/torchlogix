{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034eb1d6",
   "metadata": {},
   "source": [
    "### Thoughts on how to represent higher-precision numbers in logic gate networks\n",
    "During trainig, the model uses real-valued logic that can handle floats. The number of bits to represent the inputs can be configured to optimize training performance like so [link](https://github.com/Felix-Petersen/difflogic/blob/469702c01ff0bfac9cdc6a395134252e11a56bd8/experiments/main.py#L286C9-L286C88):\n",
    "```\n",
    "x = x.to(BITS_TO_TORCH_FLOATING_POINT_TYPE[args.training_bit_count]).to('cuda')\n",
    "```\n",
    "Compiled logic gate networks apply binary logic gate networks to binary inputs. Hence, all inputs are first transformed to type bool like so [link](https://github.com/Felix-Petersen/difflogic/blob/469702c01ff0bfac9cdc6a395134252e11a56bd8/experiments/main.py#L370\n",
    "):\n",
    "```\n",
    "data = torch.nn.Flatten()(data).bool().numpy()\n",
    "```\n",
    "PyTorch's `bool()` maps any non-zero number to `True`. Hence, for MNIST, even very dim pixels with grey scale value of 0.01 are mapped to `True`. This is acceptable as an MNIST digit can still be identified in such aggresive binarization since most pixels outisde the actual drawn digit are exactly zero.\n",
    "\n",
    "For CIFAR-10, on the other hand, much information would be lost with this approach. The original authors therefore apply the following transformation to the input data [link](https://github.com/Felix-Petersen/difflogic/blob/469702c01ff0bfac9cdc6a395134252e11a56bd8/experiments/main.py#L55C4-L63C11):\n",
    "```\n",
    "transform = lambda x: torch.cat([(x > (i + 1) / 4).float() for i in range(3)], dim=0)\n",
    "```\n",
    "This splits the float input values into three booleans, effectively creating a 3-bit representation for each float number, which is then concatenated along the first axis. Hence, the 3x32x32 float images are transformed into a 9x32x32 boolean tensor, retaining at least intensity information.\n",
    "\n",
    "This is very similar to what we independently came up with for CICADA, where we represented the 18x14 maps of 10-bit integers as an 18x14x10 tensor of booleans. Two differences arise: Firstly, we deploy logarithmic intervals instead of linear ones (which allows lossless binary representation). Secondly, we used the tensorflow-typical h,w,c notation instead of the pytorch-typical one of c,h,w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "123f2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Boolean Conversion (MNIST-style) ===\n",
      "Original:\n",
      "tensor([[0.0000, 0.0100],\n",
      "        [0.5000, 1.0000]])\n",
      "Bool:\n",
      "tensor([[False,  True],\n",
      "        [ True,  True]])\n",
      "\n",
      "=== Multi-threshold (CIFAR-10-style) ===\n",
      "Original RGB shape: torch.Size([3, 2, 2])\n",
      "Multi-threshold shape: torch.Size([9, 2, 2])\n",
      "Thresholded (9 channels):\n",
      "tensor([[[0., 1.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 1.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "\n",
      "=== CICADA-style Bit Decomposition ===\n",
      "Original integers: tensor([[ 5, 12],\n",
      "        [ 3, 15]])\n",
      "Bit decomposed shape: torch.Size([2, 2, 4])\n",
      "Bit decomposed:\n",
      "tensor([[[ True, False,  True, False],\n",
      "         [False, False,  True,  True]],\n",
      "\n",
      "        [[ True,  True, False, False],\n",
      "         [ True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=== Simple Boolean Conversion (MNIST-style) ===\")\n",
    "mnist_like = torch.tensor([[0.0, 0.01], [0.5, 1.0]])\n",
    "print(f\"Original:\\n{mnist_like}\")\n",
    "print(f\"Bool:\\n{mnist_like.bool()}\")\n",
    "\n",
    "print(\"\\n=== Multi-threshold (CIFAR-10-style) ===\")\n",
    "# 3x2x2 RGB image\n",
    "cifar_like = torch.tensor([[[0.1, 0.4], [0.7, 0.2]],  # R channel\n",
    "                           [[0.6, 0.9], [0.3, 0.8]],  # G channel  \n",
    "                           [[0.2, 0.5], [0.1, 0.7]]])  # B channel\n",
    "print(f\"Original RGB shape: {cifar_like.shape}\")\n",
    "# Apply 3 thresholds and concatenate along channel dimension\n",
    "thresholded = torch.cat([(cifar_like > (i + 1) / 4).float() for i in range(3)], dim=0)\n",
    "print(f\"Multi-threshold shape: {thresholded.shape}\")\n",
    "print(f\"Thresholded (9 channels):\\n{thresholded}\")\n",
    "\n",
    "print(\"\\n=== CICADA-style Bit Decomposition ===\")\n",
    "integers = torch.tensor([[5, 12], [3, 15]])  # 4-bit integers\n",
    "print(f\"Original integers: {integers}\")\n",
    "bit_decomposed = torch.stack([((integers // (2**i)) % 2).bool() for i in range(4)], dim=-1)\n",
    "print(f\"Bit decomposed shape: {bit_decomposed.shape}\")\n",
    "print(f\"Bit decomposed:\\n{bit_decomposed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16805f53",
   "metadata": {},
   "source": [
    "### What do `PackBitsTensor` and `num_bits` do then?\n",
    "The class `CompiledLogicNet` takes an argument `num_bits` at initialization. I think this has sparked some confusion because it looks at first glance like the number of bits used to represent float inputs. That is not the case. Instead, `num_bits` and `PackBitsTensor` only control the batching of inputs. They are only used for performance optimization and have no effect on the precision of the inputs or predictions of the model!\n",
    "\n",
    "Some more code below to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c572ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "from neurodifflogic.difflogic.compiled_model import CompiledLogicNet\n",
    "from neurodifflogic.models.difflog_layers.linear import GroupSum, LogicLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89694c7c",
   "metadata": {},
   "source": [
    "Let's create a super simple model (single AND gate) and verify it acts as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = LogicLayer(in_dim=2, out_dim=1, connections=\"unique\", implementation=\"python\", device=\"cpu\")\n",
    "layer.weight.data = torch.zeros(1, 16)\n",
    "layer.weight.data[0, 1] = 100  # Set weight for the AND operation (A*B)\n",
    "model = torch.nn.Sequential(layer, GroupSum(1))\n",
    "\n",
    "# binary AND truth table that should work in all cases\n",
    "test_cases = [((0, 0), 0), ((0, 1), 0), ((1, 0), 0), ((1, 1), 1)]\n",
    "for (x, y), expected in test_cases:\n",
    "    assert np.isclose(model(torch.tensor([x, y])).item(), expected)\n",
    "\n",
    "# this should only work for the non-compiled model, as it relies on real-valued logic\n",
    "test_cases = [((0.5, 0.5), 0.25)]\n",
    "for (x, y), expected in test_cases:\n",
    "    assert np.isclose(model(torch.tensor([x, y])).item(), expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea87684",
   "metadata": {},
   "source": [
    "Okay, let's compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98e7610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GroupSum layer with 1 classes\n",
      "Parsed 0 conv, 0 pooling, 1 linear layers\n",
      "Layer execution order: [('linear', 0)]\n",
      "Compiling finished in 0.088 seconds.\n"
     ]
    }
   ],
   "source": [
    "model.train(False)\n",
    "\n",
    "compiled_model = CompiledLogicNet(\n",
    "    model=model, num_bits=8, cpu_compiler=\"gcc\", verbose=True\n",
    ")\n",
    "compiled_model.compile(save_lib_path=\"minimal_example.so\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3157bfe7",
   "metadata": {},
   "source": [
    "We used num_bits=8, so we need a multiple of 8-bits for the inputs. Since our model takes two inputs, we use a tensor of shape (4, 2). Using only 2 examples or increasing to num_bits=16 would fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56ffbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "tensor([[0.0000, 0.1000],\n",
      "        [0.2000, 0.3000],\n",
      "        [0.4000, 0.5000],\n",
      "        [0.6000, 0.7000]])\n",
      "inputs = \n",
      "[[False  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]]\n",
      "preds = \n",
      "tensor([[0.0000],\n",
      "        [0.0600],\n",
      "        [0.2000],\n",
      "        [0.4200]])\n",
      "preds_compiled = \n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 0.1],\n",
    "                  [0.2, 0.3],\n",
    "                  [0.4, 0.5],\n",
    "                  [0.6, 0.7]])\n",
    "\n",
    "binary_inputs = X.bool().numpy()\n",
    "\n",
    "preds = model(X)\n",
    "preds_compiled = compiled_model(binary_inputs)\n",
    "\n",
    "print(f\"X = \\n{X}\")\n",
    "print(f\"inputs = \\n{binary_inputs}\")\n",
    "print(f\"preds = \\n{preds}\")\n",
    "print(f\"preds_compiled = \\n{preds_compiled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f279de5",
   "metadata": {},
   "source": [
    "This was the MNIST-like approach, where quite some information is lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4036c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GroupSum layer with 1 classes\n",
      "Parsed 0 conv, 0 pooling, 1 linear layers\n",
      "Layer execution order: [('linear', 0)]\n",
      "Compiling finished in 0.078 seconds.\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "X = \n",
      "tensor([[0.0000, 0.5000],\n",
      "        [0.7000, 0.9000],\n",
      "        [0.7000, 0.9000],\n",
      "        [0.7000, 0.9000]])\n",
      "inputs = \n",
      "[[False  True False False]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]]\n",
      "preds = \n",
      "tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "preds_compiled = \n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "layer = LogicLayer(in_dim=4, out_dim=2, connections=\"unique\", implementation=\"python\", device=\"cpu\")\n",
    "model = torch.nn.Sequential(layer, GroupSum(1))\n",
    "\n",
    "model.train(False)\n",
    "\n",
    "compiled_model = CompiledLogicNet(\n",
    "    model=model, num_bits=8, cpu_compiler=\"gcc\", verbose=True\n",
    ")\n",
    "compiled_model.compile(save_lib_path=\"minimal_example.so\", verbose=False)\n",
    "\n",
    "X = torch.tensor([[0.0, 0.1],\n",
    "                  [0.2, 0.3],\n",
    "                  [0.4, 0.5],\n",
    "                  [0.6, 0.7]])\n",
    "\n",
    "# apply 1 threshold to each input\n",
    "thresholded = torch.cat([(X > (i + 1) / 3).float() for i in range(2)], dim=1)\n",
    "print(thresholded)\n",
    "preds = model(thresholded)\n",
    "binary_inputs = thresholded.bool().numpy()\n",
    "\n",
    "preds = model(thresholded)\n",
    "preds_compiled = compiled_model(binary_inputs)\n",
    "\n",
    "print(f\"X = \\n{X}\")\n",
    "print(f\"inputs = \\n{binary_inputs}\")\n",
    "print(f\"preds = \\n{preds}\")\n",
    "print(f\"preds_compiled = \\n{preds_compiled}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
